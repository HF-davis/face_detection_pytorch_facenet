{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfacae4",
   "metadata": {
    "id": "5bfacae4",
    "outputId": "497e2fc5-5973-49fd-9075-c45b8709df22",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81093341",
   "metadata": {
    "id": "81093341"
   },
   "outputs": [],
   "source": [
    "#import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1f6663",
   "metadata": {
    "id": "dd1f6663",
    "outputId": "5ba8fb84-17f0-4646-ea85-00ea2ed49999",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c49a9c",
   "metadata": {
    "id": "26c49a9c",
    "outputId": "688fc6b4-de83-4d89-d66d-c6962a3aa2d0"
   },
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780ecc1b",
   "metadata": {
    "id": "780ecc1b",
    "outputId": "32b362bc-d644-4294-fd36-9384b0a1da88",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e57d916",
   "metadata": {
    "id": "6e57d916"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce498555",
   "metadata": {
    "id": "ce498555",
    "outputId": "f7a3e7df-8e6f-4626-beb6-4a2bb53763ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cacde20",
   "metadata": {
    "id": "2cacde20"
   },
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,keep_all=False,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de2dfdba",
   "metadata": {
    "id": "de2dfdba"
   },
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980f0a54",
   "metadata": {
    "id": "980f0a54"
   },
   "outputs": [],
   "source": [
    "workers = 0 if os.name == 'nt' else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4cb7c9d",
   "metadata": {
    "id": "e4cb7c9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#aplicar filtros a la imagen de entrenamiento, data augmentation\\nfrom PIL import Image, ImageDraw, ImageFilter\\n\\nfilters = {\\n    \"Blur\": ImageFilter.BLUR,\\n    \"Contour\": ImageFilter.CONTOUR,\\n    \"Detail\": ImageFilter.DETAIL,\\n    \"Edge Enhance\": ImageFilter.EDGE_ENHANCE,\\n    \"Edge Enhance More\": ImageFilter.EDGE_ENHANCE_MORE,\\n    \"Emboss\": ImageFilter.EMBOSS,\\n    \"Find Edges\": ImageFilter.FIND_EDGES,\\n    \"Sharpen\": ImageFilter.SHARPEN,\\n    \"Smooth\": ImageFilter.SMOOTH,\\n    \"Smooth More\": ImageFilter.SMOOTH_MORE,\\n    \"Box Blur\": ImageFilter.BoxBlur(10),\\n    \"Gaussian Blur\": ImageFilter.GaussianBlur(25),\\n    \"Unsharp Mark\": ImageFilter.UnsharpMask,\\n}\\n\\nif __name__ == \"__main__\":\\n    for key, value in filters.items():\\n        with Image.open(\"./p/train/Jeremy_Meeks_Mug_Shot.jpg\") as im:\\n            im = im.filter(value)\\n            im.save(f\"./p/train/{key}.jpg\")\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#aplicar filtros a la imagen de entrenamiento, data augmentation\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "\n",
    "filters = {\n",
    "    \"Blur\": ImageFilter.BLUR,\n",
    "    \"Contour\": ImageFilter.CONTOUR,\n",
    "    \"Detail\": ImageFilter.DETAIL,\n",
    "    \"Edge Enhance\": ImageFilter.EDGE_ENHANCE,\n",
    "    \"Edge Enhance More\": ImageFilter.EDGE_ENHANCE_MORE,\n",
    "    \"Emboss\": ImageFilter.EMBOSS,\n",
    "    \"Find Edges\": ImageFilter.FIND_EDGES,\n",
    "    \"Sharpen\": ImageFilter.SHARPEN,\n",
    "    \"Smooth\": ImageFilter.SMOOTH,\n",
    "    \"Smooth More\": ImageFilter.SMOOTH_MORE,\n",
    "    \"Box Blur\": ImageFilter.BoxBlur(10),\n",
    "    \"Gaussian Blur\": ImageFilter.GaussianBlur(25),\n",
    "    \"Unsharp Mark\": ImageFilter.UnsharpMask,\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for key, value in filters.items():\n",
    "        with Image.open(\"./p/train/Jeremy_Meeks_Mug_Shot.jpg\") as im:\n",
    "            im = im.filter(value)\n",
    "            im.save(f\"./p/train/{key}.jpg\")\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca30ea8b",
   "metadata": {
    "id": "ca30ea8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef collate_fn(x):\\n    return x[0]\\n\\ndataset = datasets.ImageFolder('./train')\\ndataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\\nloader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder('./train')\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d31cb0",
   "metadata": {
    "id": "56d31cb0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nname_list=[]\\nembedding_list=[]\\nfor img, idx in loader:\\n    face, prob = mtcnn(img, return_prob=True) \\n    if face is not None and prob>0.92:\\n        emb = resnet(face.unsqueeze(0)).to(device) \\n        embedding_list.append(emb.detach()) \\n        name_list.append(dataset.idx_to_class[idx]) \\n\\ndata = [embedding_list, name_list] \\ntorch.save(data, 'data.pt') # saving data.pt file\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "name_list=[]\n",
    "embedding_list=[]\n",
    "for img, idx in loader:\n",
    "    face, prob = mtcnn(img, return_prob=True) \n",
    "    if face is not None and prob>0.92:\n",
    "        emb = resnet(face.unsqueeze(0)).to(device) \n",
    "        embedding_list.append(emb.detach()) \n",
    "        name_list.append(dataset.idx_to_class[idx]) \n",
    "\n",
    "data = [embedding_list, name_list] \n",
    "torch.save(data, 'data.pt') # saving data.pt file\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0523a2d",
   "metadata": {
    "id": "b0523a2d"
   },
   "outputs": [],
   "source": [
    "load_data=torch.load('data.pt')\n",
    "embedding_list=load_data[0]\n",
    "name_list=load_data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "223a06d2",
   "metadata": {
    "id": "223a06d2",
    "outputId": "d3ab14d6-fd7a-4a25-8080-4da0bd52bd99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimg=cv2.imread(\\'./val/Davis Alderete/310.png\\')\\nimg_cropped,prob=mtcnn(img,return_prob=True)\\n\\n\\nboxes,_=mtcnn.detect(img)\\n\\nif prob>0.90:\\n    img_embedding=resnet(img_cropped.unsqueeze(0)).to(device)\\n    dist_list=[]\\n    for idx,emb_db in enumerate(embedding_list):\\n        dist=torch.dist(img_embedding,emb_db).item()\\n        dist_list.append(dist)\\n    min_dist=min(dist_list)\\n    min_dist_idx=dist_list.index(min_dist)\\n    name=name_list[min_dist_idx]\\n\\n    box=boxes[0]\\n    original_img=img.copy()\\n    if min_dist<0.90:\\n        img=cv2.putText(img,name+\\' \\'+str(min_dist),(int(box[0]),int(box[1])),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),1,cv2.LINE_AA)\\n    img=cv2.rectangle(img,(int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(255,0,0),2)\\n\\n\\n\\nwhile True:\\n    cv2.imshow(\"Smarcity \",img)\\n    cv2.waitKey(0)\\n    #sys.exit() # to exit from all the processes\\n \\ncv2.destroyAllWindows() # destroy all windows\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "img=cv2.imread('./val/Davis Alderete/310.png')\n",
    "img_cropped,prob=mtcnn(img,return_prob=True)\n",
    "\n",
    "\n",
    "boxes,_=mtcnn.detect(img)\n",
    "\n",
    "if prob>0.90:\n",
    "    img_embedding=resnet(img_cropped.unsqueeze(0)).to(device)\n",
    "    dist_list=[]\n",
    "    for idx,emb_db in enumerate(embedding_list):\n",
    "        dist=torch.dist(img_embedding,emb_db).item()\n",
    "        dist_list.append(dist)\n",
    "    min_dist=min(dist_list)\n",
    "    min_dist_idx=dist_list.index(min_dist)\n",
    "    name=name_list[min_dist_idx]\n",
    "\n",
    "    box=boxes[0]\n",
    "    original_img=img.copy()\n",
    "    if min_dist<0.90:\n",
    "        img=cv2.putText(img,name+' '+str(min_dist),(int(box[0]),int(box[1])),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),1,cv2.LINE_AA)\n",
    "    img=cv2.rectangle(img,(int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(255,0,0),2)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Smarcity \",img)\n",
    "    cv2.waitKey(0)\n",
    "    #sys.exit() # to exit from all the processes\n",
    " \n",
    "cv2.destroyAllWindows() # destroy all windows\n",
    "\n",
    "'''\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac60d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognition(img,emb_list):\n",
    "    \n",
    "    img_cropped_list,prob=mtcnn(img,return_prob=True)\n",
    "    \n",
    "    boxes,_=mtcnn.detect(img)\n",
    "    if img_cropped_list is not None:\n",
    "\n",
    "        if prob>0.80:\n",
    "                img_embedding=resnet(img_cropped_list.unsqueeze(0)).detach()\n",
    "                dist_list=[]\n",
    "                    \n",
    "                for idx,emb_db in enumerate(emb_list):\n",
    "                    dist=torch.dist(img_embedding,emb_db).item()\n",
    "                    dist_list.append(dist)\n",
    "                min_dist=min(dist_list)\n",
    "                min_dist_idx=dist_list.index(min_dist)\n",
    "                name=name_list[min_dist_idx]\n",
    "\n",
    "                box=boxes[0]\n",
    "                original_img=img.copy()\n",
    "                if min_dist<0.90:\n",
    "                    img=cv2.putText(img,name+' '+str(min_dist),(int(box[0]),int(box[1])),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),1,cv2.LINE_AA)\n",
    "                img=cv2.rectangle(img,(int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(255,0,0),2)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f670044",
   "metadata": {
    "id": "1f670044"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    }
   ],
   "source": [
    "##webcam implemented\n",
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        print(\"fail to grab frame, try again\")\n",
    "        break\n",
    "    img=recognition(frame,embedding_list)\n",
    "    cv2.imshow('webCam',img)\n",
    "    if cv2.waitKey(20)==27:\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b59bf43c",
   "metadata": {
    "id": "b59bf43c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\naligned = torch.stack(aligned).to(device)\\nembeddings = resnet(aligned).detach().cpu()\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "aligned = torch.stack(aligned).to(device)\n",
    "embeddings = resnet(aligned).detach().cpu()\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332a83c",
   "metadata": {
    "id": "6332a83c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3264530b",
   "metadata": {
    "id": "3264530b",
    "outputId": "b883d446-c8cc-457e-f51e-c311affaee62",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\ndists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\\npd.DataFrame(dists, columns=names, index=names)\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
    "pd.DataFrame(dists, columns=names, index=names)\n",
    "\n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc557b74f5c7d96f3a4fff2167a95a4252e316909755ef10c67da981ac2e9136"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
